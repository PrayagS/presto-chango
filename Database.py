import os
import random
from Song import song_recipe
import pickle


# class DataPoint:
#     def __init__(self, time, song_id):
#         self.time = time
#         self.song_id = song_id

def hash_window(filtered_bin):
    """
    :param filtered_bin: A filtered bin of a window generated by filter_spectrogram
    :return: hash value of the particular bin
    """

    """
    Note that we must assume that the recording is not done in perfect conditions (i.e., a “deaf room”),
    and as a result we must include a fuzz factor.
    Fuzz factor analysis should be taken seriously, and in a real system,
    the program should have an option to set this parameter based on the conditions of the recording.
    """
    fuz_factor = 2  # for error correction TODO: figure out why?

    return (filtered_bin[3] - (filtered_bin[3] % fuz_factor)) * 1e8 + (
        filtered_bin[2] - (filtered_bin[2] % fuz_factor)) * 1e5 + (
        filtered_bin[1] - (filtered_bin[1] % fuz_factor)) * 1e2 + (
        filtered_bin[0] - (filtered_bin[0] % fuz_factor))


def hash_song(song_id, filtered_bins, hash_dictionary):
    """
    Modifies hash_dictionary to map data of the given song_id
    :param song_id: id of the particular song
    :param filtered_bins: bins generated by song_recipe
    :param hash_dictionary
    """
    for i, filtered_bin in enumerate(filtered_bins):
        try:
            hash_dictionary[hash_window(filtered_bin)].append((song_id, i))
        except KeyError:
            hash_dictionary[hash_window(filtered_bin)] = [(song_id, i)]


def hash_sample(filtered_bins):
    sample_dictionary = {}
    for i, filtered_bin in enumerate(filtered_bins):
        try:
            sample_dictionary[hash_window(filtered_bin)].append(i)
        except KeyError:
            sample_dictionary[hash_window(filtered_bin)] = [i]
    return sample_dictionary


def create_database():
    """
    :return: song_to_id - Maps song names to generated ids, id_to_song - Maps ids to song
    hash_dictionary - Maps hash values to associated song ids and offset values
    """
    song_to_id = {}
    id_to_song = {}
    hash_dictionary = {}
    random_ids = random.sample(range(1000), len(os.listdir('Songs')))
    for song_id, filename in zip(random_ids, os.listdir('Songs')):
        print(filename)
        # song_id = int(random() * 1000)
        # while song_id in song_to_id.items():
        #     song_id = int(random() * 1000)
        song_to_id[filename] = song_id
        id_to_song[song_id] = filename
        filtered_bins = song_recipe("Songs/" + filename)
        hash_song(song_id, filtered_bins, hash_dictionary)
    with open('Songs.pickle', 'wb') as f:
        pickle.dump(song_to_id, f)
        pickle.dump(id_to_song, f)
        pickle.dump(hash_dictionary, f)
    return song_to_id, id_to_song, hash_dictionary


def load_database():
    with open('Songs.pickle', 'rb') as f:
        song_to_id = pickle.load(f)
        id_to_song = pickle.load(f)
        hash_dictionary = pickle.load(f)
    return song_to_id, id_to_song, hash_dictionary


def find_song(hash_dictionary, sample_dictionary, id_to_song):
    probability_song = {}
    for song_id in id_to_song.keys():
        probability_song[song_id] = 0
    for hash_value_cur in sample_dictionary.keys():
        if hash_value_cur in hash_dictionary.keys():
            for item in hash_dictionary[hash_value_cur]:
                song_id, offset = item
                probability_song[song_id] += len(
                    sample_dictionary[hash_value_cur])
        # for hash_value, item in hash_dictionary:
        #     song_id, offset = item
        #     if hash_value == hash_value_cur:
        #         probability_song[song_id] += 1
    probable_song = None
    max_probability = 0
    print(probability_song)
    print(id_to_song)
    for song_id, probability in probability_song.items():
        if probability > max_probability:
            max_probability = probability
            probable_song = song_id
    return probable_song
    # relative_offsets = {}
    # for song_id in id_to_song.keys():
    #     relative_offsets[song_id] = {}
    # for hash_value in hash_dictionary_cur.keys():
    #     if hash_value in hash_dictionary.keys():
    #         song_id, offset = hash_dictionary[hash_value]
    #         song_offset = hash_dictionary_cur[hash_value]
    #         try:
    #             # hash_values = relative_offsets[song_id]
    #             relative_offsets[song_id][hash_value][offset - song_offset] += 1
    #         except KeyError:
    #             relative_offsets[song_id][hash_value] = {}
    #             relative_offsets[song_id][hash_value][offset - song_offset] = 1
    #             # try:
    #             #     offsets = relative_offsets[song_id][hash_value]
    #             #     offsets[offset - song_offset] += 1
    #             # except KeyError:
    #
    #             # relative_offets[song_id].append(offset - song_offset)
    #         # except KeyError:
    #         #     relative_offsets[song_id] = {}
    #         #     relative_offsets[song_id][hash_value]


if __name__ == "__main__":
    # song_to_id, id_to_song, hash_dictionary = create_database()
    # song_to_id, id_to_song, hash_dictionary = load_database()
    # print(song_to_id)
    # print(id_to_song)
    # print(hash_dictionary)
    # for keys in hash_dictionary.keys():
    #     print(keys)
    # for item in hash_dictionary.items():
    #     print(item)
    create_database()
    filtered_bins_sample = song_recipe("Renai30s.wav")
    sample_dictionary = hash_sample(filtered_bins_sample)
    song_to_id, id_to_song, hash_dictionary = load_database()
    probable_song = find_song(hash_dictionary, sample_dictionary, id_to_song)
    print("Final answer:")
    print(id_to_song[probable_song])
