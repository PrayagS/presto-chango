import os
import random
from Song import song_recipe
import pickle


# class DataPoint:
#     def __init__(self, time, song_id):
#         self.time = time
#         self.song_id = song_id

def hash_window(filtered_bin):
    """
    :param filtered_bin: A filtered bin of a window generated by filter_spectrogram
    :return: hash value of the particular bin
    """

    """
    Note that we must assume that the recording is not done in perfect conditions (i.e., a “deaf room”),
    and as a result we must include a fuzz factor.
    Fuzz factor analysis should be taken seriously, and in a real system,
    the program should have an option to set this parameter based on the conditions of the recording.
    """
    fuz_factor = 2  # for error correction TODO: figure out why?

    return (filtered_bin[3] - (filtered_bin[3] % fuz_factor)) * 1e8 + (
            filtered_bin[2] - (filtered_bin[2] % fuz_factor)) * 1e5 + (
                   filtered_bin[1] - (filtered_bin[1] % fuz_factor)) * 1e2 + (
                   filtered_bin[0] - (filtered_bin[0] % fuz_factor))


def hash_song(song_id, filtered_bins, hash_dictionary):
    """
    Modifies hash_dictionary to map data of the given song_id
    :param song_id: id of the particular song
    :param filtered_bins: bins generated by song_recipe
    :param hash_dictionary
    """
    for i, filtered_bin in enumerate(filtered_bins):
        try:
            hash_dictionary[hash_window(filtered_bin)].append((song_id, i))
        except KeyError:
            hash_dictionary[hash_window(filtered_bin)] = [(song_id, i)]


def create_database():
    """
    :return: song_to_id - Maps song names to generated ids, id_to_song - Maps ids to song
    hash_dictionary - Maps hash values to associated song ids and offset values
    """
    song_to_id = {}
    id_to_song = {}
    hash_dictionary = {}
    random_ids = random.sample(range(1000), len(os.listdir('Songs')))
    for song_id, filename in zip(random_ids, os.listdir('Songs')):
        print(filename)
        # song_id = int(random() * 1000)
        # while song_id in song_to_id.items():
        #     song_id = int(random() * 1000)
        song_to_id[filename] = song_id
        id_to_song[song_id] = filename
        filtered_bins = song_recipe("Songs/" + filename)
        hash_song(song_id, filtered_bins, hash_dictionary)
    with open('Songs.pickle', 'wb') as f:
        pickle.dump(song_to_id, f)
        pickle.dump(id_to_song, f)
        pickle.dump(hash_dictionary, f)
    return song_to_id, id_to_song, hash_dictionary


def load_database():
    with open('Songs.pickle', 'rb') as f:
        song_to_id = pickle.load(f)
        id_to_song = pickle.load(f)
        hash_dictionary = pickle.load(f)
    return song_to_id, id_to_song, hash_dictionary


if __name__ == "__main__":
    # song_to_id, id_to_song, hash_dictionary = create_database()
    song_to_id, id_to_song, hash_dictionary = load_database()
    print(song_to_id)
    print(id_to_song)
    print(hash_dictionary)
    for keys in hash_dictionary.keys():
        print(keys)
    for item in hash_dictionary.items():
        print(item)
